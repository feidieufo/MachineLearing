import torch
import torchvision
import torchvision.transforms as transforms
import numpy as np
import matplotlib.pyplot as plt

import torch.nn as nn
import torch.nn.functional as F

batch_size = 4
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

transform = transforms.Compose(
    [transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

trainset = torchvision.datasets.MNIST(root='./data', train=True,
                                        download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                          shuffle=True, num_workers=0)

testset = torchvision.datasets.MNIST(root='./data', train=False,
                                       download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,
                                         shuffle=False, num_workers=0)

def imshow(img):
    img = img / 2 + 0.5     # unnormalize
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()


# get some random training images
# dataiter = iter(trainloader)
# images, labels = dataiter.next()

for data in trainloader:
    images, labels = data
# show images
    imshow(torchvision.utils.make_grid(images))

GEN_INPUT = 1000

class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.conv1 = nn.Conv2d(1, 64, 5, stride=1)
        self.conv2 = nn.Conv2d(64, 128, 5, stride=1)
        self.fcn1 = nn.Linear(20*20*128, 1024)
        self.fcn2 = nn.Linear(1024, 1)

    def forward(self, x):
        x = F.leaky_relu(self.conv1(x))
        x = F.leaky_relu(self.conv2(x))
        x = x.view(-1, 20*20*128)
        x = F.leaky_relu(self.fcn1(x))
        x = F.sigmoid(self.fcn2)

        return x

class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()
        self.fcn1 = nn.Linear(GEN_INPUT, 1024)
        self.fcn2 = nn.Linear(1024, 20*20*128)

        self.conv1 = nn.ConvTranspose2d(128, 64, 5, stride=1)
        self.conv2 = nn.ConvTranspose2d(64, 1, 5, stride=1)

    def forward(self, x):
        x = F.relu(self.fcn1(x))
        x = F.relu(self.fcn2(x))
        x = x.view(-1, 20, 20, 128)
        x = F.relu(self.conv1(x))
        x = F.tan(self.conv2(x))

        return x

netD = Discriminator().to(device)
netG = Generator().to(device)

real_label = 1
fake_label = 0
loss_fn = nn.BCELoss()
optimizerD = torch.optim.Adam(netD.parameters(), lr=0.01)
optimizerG = torch.optim.Adam(netG.parameters(), lr=0.01)

for epoch in range(1000):
    for i, data in enumerate(trainloader):
        netD.zero_grad()
        real = data[0].to(device)
        label = torch.full((real.shape(0),), real_label, device=device)
        predict = netD(real).view(-1)
        lossD_real = loss_fn(predict, label)
        lossD_real.backward()

        noise = torch.randn((real.shape(0), GEN_INPUT))
        label.fill_(fake_label)
        fake = netG(noise)
        predict = netD(fake.detach()).view(-1)
        lossD_fake = loss_fn(predict, label)
        lossD_fake.backward()

        optimizerD.step()

        netG.zero_grad()
